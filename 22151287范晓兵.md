github账号为https://github.com/ikutalilas/ikutalilas

深度学习模型分析地址为https://github.com/TommyZihao/zihaopytorch

本次实验目的为搭建一个最简单的全连接神经网络，并且通过Dropout方法消除过拟合现象

训练一个四层的全连接神经网络，神经网络的输入为28 * 28 = 784 个像素，第一个隐含层包含256个神经元，第二个隐含层包含128个神经元，第三个隐含层包含64个神经元，输出层输出10个结果，对应图片的10种分类

训练15轮

可以看到，虽然训练误差一直在下降，但测试误差居高不下，虽然误差很大，但大部分时候依旧能做出正确判断，但是有时候预测概率只有百分之三四十的把握，不能做到十有八九的确定。

为此可以采用Dropout方法防止过拟合也就是在每次正向推断训练神经元的时候随机“掐死”一部分神经元，阻断其输入输出，这样可以起到正则化的作用。所有神经元处于平等地位，防止过拟合。

训练之后可以看到，训练误差和测试误差都随学习次数增加逐渐降低，没有出现“高分低能”和“死记硬背”的过拟合现象，这其实是Dropout正则化的功劳。
